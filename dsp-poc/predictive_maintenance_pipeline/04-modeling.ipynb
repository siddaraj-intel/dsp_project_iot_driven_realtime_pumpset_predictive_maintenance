{"cells":[{"cell_type":"markdown","id":"248e4277","metadata":{"id":"248e4277"},"source":["# 04 - Modeling\n","\n","\n","## Objective\n","Stratified binning, baseline models, event-flag features, 5-fold CV stability, and artifact saving.\n","\n","---\n","\n","### Run order\n","Execute notebooks in numeric order: 01 → 02 → 03 → 04 → 05. Each notebook mounts Google Drive and reads/writes intermediate artifacts so it can run independently.\n","\n","---\n"]},{"cell_type":"code","execution_count":3,"id":"3d862812","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1403711,"status":"ok","timestamp":1764694755151,"user":{"displayName":"SANGRAM KUMAR Y","userId":"10569401132669237625"},"user_tz":-330},"id":"3d862812","outputId":"cbc54b98-796f-4672-b9a9-e0b8757341aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted!\n","Loaded preprocessed: (166441, 54)\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075207 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 12506\n","[LightGBM] [Info] Number of data points in the train set: 79891, number of used features: 50\n","[LightGBM] [Info] Start training from score 288.777632\n","Training until validation scores don't improve for 200 rounds\n","[200]\tvalid_0's rmse: 26.5286\tvalid_0's l2: 703.765\n","[400]\tvalid_0's rmse: 22.2663\tvalid_0's l2: 495.788\n","[600]\tvalid_0's rmse: 20.1368\tvalid_0's l2: 405.489\n","[800]\tvalid_0's rmse: 18.9196\tvalid_0's l2: 357.952\n","[1000]\tvalid_0's rmse: 18.0669\tvalid_0's l2: 326.412\n","[1200]\tvalid_0's rmse: 17.3689\tvalid_0's l2: 301.678\n","[1400]\tvalid_0's rmse: 16.9294\tvalid_0's l2: 286.605\n","[1600]\tvalid_0's rmse: 16.6099\tvalid_0's l2: 275.888\n","[1800]\tvalid_0's rmse: 16.3357\tvalid_0's l2: 266.855\n","[2000]\tvalid_0's rmse: 16.1402\tvalid_0's l2: 260.507\n","[2200]\tvalid_0's rmse: 15.9429\tvalid_0's l2: 254.175\n","[2400]\tvalid_0's rmse: 15.7721\tvalid_0's l2: 248.758\n","[2600]\tvalid_0's rmse: 15.6335\tvalid_0's l2: 244.408\n","[2800]\tvalid_0's rmse: 15.5307\tvalid_0's l2: 241.202\n","[3000]\tvalid_0's rmse: 15.4269\tvalid_0's l2: 237.988\n","[3200]\tvalid_0's rmse: 15.3163\tvalid_0's l2: 234.59\n","[3400]\tvalid_0's rmse: 15.2534\tvalid_0's l2: 232.665\n","[3600]\tvalid_0's rmse: 15.184\tvalid_0's l2: 230.555\n","[3800]\tvalid_0's rmse: 15.1307\tvalid_0's l2: 228.937\n","[4000]\tvalid_0's rmse: 15.0647\tvalid_0's l2: 226.946\n","[4200]\tvalid_0's rmse: 15.0067\tvalid_0's l2: 225.2\n","[4400]\tvalid_0's rmse: 14.9591\tvalid_0's l2: 223.774\n","[4600]\tvalid_0's rmse: 14.9116\tvalid_0's l2: 222.355\n","[4800]\tvalid_0's rmse: 14.8633\tvalid_0's l2: 220.919\n","[5000]\tvalid_0's rmse: 14.8261\tvalid_0's l2: 219.813\n","Did not meet early stopping. Best iteration is:\n","[5000]\tvalid_0's rmse: 14.8261\tvalid_0's l2: 219.813\n","0:\tlearn: 218.3736616\ttest: 217.8614754\tbest: 217.8614754 (0)\ttotal: 39.9ms\tremaining: 3m 19s\n","200:\tlearn: 44.1752349\ttest: 45.8373904\tbest: 45.8373904 (200)\ttotal: 6.78s\tremaining: 2m 41s\n","400:\tlearn: 31.9767008\ttest: 34.0313155\tbest: 34.0313155 (400)\ttotal: 13.9s\tremaining: 2m 39s\n","600:\tlearn: 26.3630231\ttest: 28.8121660\tbest: 28.8121660 (600)\ttotal: 21.1s\tremaining: 2m 34s\n","800:\tlearn: 23.0958911\ttest: 25.8512382\tbest: 25.8512382 (800)\ttotal: 28.2s\tremaining: 2m 27s\n","1000:\tlearn: 20.8196518\ttest: 23.7854150\tbest: 23.7854150 (1000)\ttotal: 35.6s\tremaining: 2m 22s\n","1200:\tlearn: 19.0230583\ttest: 22.1793803\tbest: 22.1793803 (1200)\ttotal: 42.4s\tremaining: 2m 14s\n","1400:\tlearn: 17.6954737\ttest: 21.0291451\tbest: 21.0291451 (1400)\ttotal: 50s\tremaining: 2m 8s\n","1600:\tlearn: 16.6430548\ttest: 20.0919369\tbest: 20.0919369 (1600)\ttotal: 56.6s\tremaining: 2m\n","1800:\tlearn: 15.7317038\ttest: 19.3089714\tbest: 19.3089714 (1800)\ttotal: 1m 4s\tremaining: 1m 54s\n","2000:\tlearn: 14.9858568\ttest: 18.7049095\tbest: 18.7049095 (2000)\ttotal: 1m 10s\tremaining: 1m 45s\n","2200:\tlearn: 14.2954535\ttest: 18.1416587\tbest: 18.1416587 (2200)\ttotal: 1m 18s\tremaining: 1m 40s\n","2400:\tlearn: 13.7105387\ttest: 17.6637557\tbest: 17.6637557 (2400)\ttotal: 1m 24s\tremaining: 1m 31s\n","2600:\tlearn: 13.2247231\ttest: 17.2876684\tbest: 17.2876684 (2600)\ttotal: 1m 32s\tremaining: 1m 25s\n","2800:\tlearn: 12.7593541\ttest: 16.9205257\tbest: 16.9205257 (2800)\ttotal: 1m 38s\tremaining: 1m 17s\n","3000:\tlearn: 12.3147240\ttest: 16.5708091\tbest: 16.5708091 (3000)\ttotal: 1m 46s\tremaining: 1m 11s\n","3200:\tlearn: 11.9103049\ttest: 16.2602589\tbest: 16.2602589 (3200)\ttotal: 1m 53s\tremaining: 1m 3s\n","3400:\tlearn: 11.5637846\ttest: 16.0239648\tbest: 16.0239648 (3400)\ttotal: 2m 1s\tremaining: 56.9s\n","3600:\tlearn: 11.2230292\ttest: 15.7605128\tbest: 15.7605128 (3600)\ttotal: 2m 7s\tremaining: 49.4s\n","3800:\tlearn: 10.9295091\ttest: 15.5575841\tbest: 15.5575841 (3800)\ttotal: 2m 15s\tremaining: 42.6s\n","4000:\tlearn: 10.6397257\ttest: 15.3392281\tbest: 15.3392281 (4000)\ttotal: 2m 21s\tremaining: 35.3s\n","4200:\tlearn: 10.3747937\ttest: 15.1600342\tbest: 15.1600342 (4200)\ttotal: 2m 29s\tremaining: 28.4s\n","4400:\tlearn: 10.1182671\ttest: 14.9719327\tbest: 14.9719327 (4400)\ttotal: 2m 35s\tremaining: 21.2s\n","4600:\tlearn: 9.8889865\ttest: 14.8256038\tbest: 14.8256038 (4600)\ttotal: 2m 43s\tremaining: 14.2s\n","4800:\tlearn: 9.6615230\ttest: 14.6909862\tbest: 14.6909862 (4800)\ttotal: 2m 49s\tremaining: 7.03s\n","4999:\tlearn: 9.4536872\ttest: 14.5566841\tbest: 14.5566841 (4999)\ttotal: 2m 57s\tremaining: 0us\n","\n","bestTest = 14.5566841\n","bestIteration = 4999\n","\n","=== Test Metrics (Baseline) ===\n","          Model       RMSE        MAE        R2\n","2      LightGBM  12.869895   6.407598  0.996744\n","3      CatBoost  13.226475   8.224581  0.996561\n","1        HistGB  18.341643  10.411294  0.993387\n","0  RandomForest  24.186902  12.696718  0.988500\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054347 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 13534\n","[LightGBM] [Info] Number of data points in the train set: 79891, number of used features: 58\n","[LightGBM] [Info] Start training from score 288.777632\n","Training until validation scores don't improve for 200 rounds\n","[200]\tvalid_0's rmse: 25.5821\tvalid_0's l2: 654.444\n","[400]\tvalid_0's rmse: 21.5522\tvalid_0's l2: 464.499\n","[600]\tvalid_0's rmse: 19.4832\tvalid_0's l2: 379.597\n","[800]\tvalid_0's rmse: 18.2389\tvalid_0's l2: 332.658\n","[1000]\tvalid_0's rmse: 17.4626\tvalid_0's l2: 304.942\n","[1200]\tvalid_0's rmse: 16.8992\tvalid_0's l2: 285.584\n","[1400]\tvalid_0's rmse: 16.4972\tvalid_0's l2: 272.157\n","[1600]\tvalid_0's rmse: 16.1328\tvalid_0's l2: 260.269\n","[1800]\tvalid_0's rmse: 15.8757\tvalid_0's l2: 252.039\n","[2000]\tvalid_0's rmse: 15.6727\tvalid_0's l2: 245.634\n","[2200]\tvalid_0's rmse: 15.5074\tvalid_0's l2: 240.478\n","[2400]\tvalid_0's rmse: 15.3208\tvalid_0's l2: 234.728\n","[2600]\tvalid_0's rmse: 15.1887\tvalid_0's l2: 230.698\n","[2800]\tvalid_0's rmse: 15.0806\tvalid_0's l2: 227.425\n","[3000]\tvalid_0's rmse: 14.9979\tvalid_0's l2: 224.937\n","[3200]\tvalid_0's rmse: 14.9051\tvalid_0's l2: 222.161\n","[3400]\tvalid_0's rmse: 14.8329\tvalid_0's l2: 220.014\n","[3600]\tvalid_0's rmse: 14.7645\tvalid_0's l2: 217.991\n","[3800]\tvalid_0's rmse: 14.7035\tvalid_0's l2: 216.192\n","[4000]\tvalid_0's rmse: 14.6415\tvalid_0's l2: 214.375\n","[4200]\tvalid_0's rmse: 14.5868\tvalid_0's l2: 212.776\n","[4400]\tvalid_0's rmse: 14.5384\tvalid_0's l2: 211.364\n","[4600]\tvalid_0's rmse: 14.49\tvalid_0's l2: 209.96\n","[4800]\tvalid_0's rmse: 14.456\tvalid_0's l2: 208.975\n","[5000]\tvalid_0's rmse: 14.4292\tvalid_0's l2: 208.201\n","Did not meet early stopping. Best iteration is:\n","[5000]\tvalid_0's rmse: 14.4292\tvalid_0's l2: 208.201\n","0:\tlearn: 218.4894096\ttest: 217.9936825\tbest: 217.9936825 (0)\ttotal: 42.2ms\tremaining: 3m 30s\n","200:\tlearn: 43.5268402\ttest: 45.1860366\tbest: 45.1860366 (200)\ttotal: 8.58s\tremaining: 3m 24s\n","400:\tlearn: 31.4488065\ttest: 33.6296175\tbest: 33.6296175 (400)\ttotal: 15s\tremaining: 2m 52s\n","600:\tlearn: 25.9770278\ttest: 28.4769865\tbest: 28.4769865 (600)\ttotal: 23.5s\tremaining: 2m 51s\n","800:\tlearn: 22.6584736\ttest: 25.4656899\tbest: 25.4656899 (800)\ttotal: 30s\tremaining: 2m 37s\n","1000:\tlearn: 20.2806637\ttest: 23.2900472\tbest: 23.2900472 (1000)\ttotal: 38.6s\tremaining: 2m 34s\n","1200:\tlearn: 18.5928929\ttest: 21.8093452\tbest: 21.8093452 (1200)\ttotal: 45.1s\tremaining: 2m 22s\n","1400:\tlearn: 17.3232305\ttest: 20.7050947\tbest: 20.7050947 (1400)\ttotal: 53.6s\tremaining: 2m 17s\n","1600:\tlearn: 16.2514267\ttest: 19.8080238\tbest: 19.8080238 (1600)\ttotal: 1m\tremaining: 2m 7s\n","1800:\tlearn: 15.3904778\ttest: 19.1023971\tbest: 19.1023971 (1800)\ttotal: 1m 8s\tremaining: 2m 2s\n","2000:\tlearn: 14.6265445\ttest: 18.4868761\tbest: 18.4868761 (2000)\ttotal: 1m 16s\tremaining: 1m 54s\n","2200:\tlearn: 13.9580597\ttest: 17.9657475\tbest: 17.9657475 (2200)\ttotal: 1m 23s\tremaining: 1m 46s\n","2400:\tlearn: 13.3623351\ttest: 17.5091197\tbest: 17.5091197 (2400)\ttotal: 1m 32s\tremaining: 1m 39s\n","2600:\tlearn: 12.8275357\ttest: 17.0990584\tbest: 17.0990584 (2600)\ttotal: 1m 38s\tremaining: 1m 31s\n","2800:\tlearn: 12.3741062\ttest: 16.7760777\tbest: 16.7760777 (2800)\ttotal: 1m 47s\tremaining: 1m 24s\n","3000:\tlearn: 11.9769124\ttest: 16.4853244\tbest: 16.4853244 (3000)\ttotal: 1m 53s\tremaining: 1m 15s\n","3200:\tlearn: 11.5797748\ttest: 16.2012786\tbest: 16.2012786 (3200)\ttotal: 2m 2s\tremaining: 1m 8s\n","3400:\tlearn: 11.2481500\ttest: 15.9758523\tbest: 15.9758523 (3400)\ttotal: 2m 8s\tremaining: 1m\n","3600:\tlearn: 10.9097360\ttest: 15.7395287\tbest: 15.7395287 (3600)\ttotal: 2m 17s\tremaining: 53.4s\n","3800:\tlearn: 10.6033442\ttest: 15.5349770\tbest: 15.5349770 (3800)\ttotal: 2m 24s\tremaining: 45.6s\n","4000:\tlearn: 10.3245780\ttest: 15.3494994\tbest: 15.3494994 (4000)\ttotal: 2m 32s\tremaining: 38.1s\n","4200:\tlearn: 10.0453590\ttest: 15.1696860\tbest: 15.1696860 (4200)\ttotal: 2m 40s\tremaining: 30.6s\n","4400:\tlearn: 9.7988976\ttest: 15.0131831\tbest: 15.0131831 (4400)\ttotal: 2m 47s\tremaining: 22.8s\n","4600:\tlearn: 9.5563577\ttest: 14.8438275\tbest: 14.8438275 (4600)\ttotal: 2m 56s\tremaining: 15.3s\n","4800:\tlearn: 9.3275848\ttest: 14.6933541\tbest: 14.6933541 (4800)\ttotal: 3m 2s\tremaining: 7.58s\n","4999:\tlearn: 9.1286461\ttest: 14.5756856\tbest: 14.5756856 (4999)\ttotal: 3m 11s\tremaining: 0us\n","\n","bestTest = 14.57568558\n","bestIteration = 4999\n","\n","=== Test Metrics AFTER adding event flags ===\n","                Model       RMSE        MAE        R2\n","2      LightGBM+Flags  12.556956   6.488911  0.996900\n","3      CatBoost+Flags  13.154257   8.065513  0.996598\n","1        HistGB+Flags  18.351175  10.269521  0.993380\n","0  RandomForest+Flags  24.627211  13.270230  0.988077\n","=== Combined Comparison (Baseline vs WithFlags) ===\n","                Model       RMSE        MAE        R2      Round\n","0            LightGBM  12.869895   6.407598  0.996744   Baseline\n","1            CatBoost  13.226475   8.224581  0.996561   Baseline\n","2              HistGB  18.341643  10.411294  0.993387   Baseline\n","3        RandomForest  24.186902  12.696718  0.988500   Baseline\n","4      LightGBM+Flags  12.556956   6.488911  0.996900  WithFlags\n","5      CatBoost+Flags  13.154257   8.065513  0.996598  WithFlags\n","6        HistGB+Flags  18.351175  10.269521  0.993380  WithFlags\n","7  RandomForest+Flags  24.627211  13.270230  0.988077  WithFlags\n","Selected best model: LightGBM+Flags (WithFlags)\n","Artifacts saved to: /content/drive/MyDrive/dsp-poc/artifacts\n"]}],"source":["\n","import os\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Ensure packages\n","!pip -q install lightgbm catboost\n","\n","import lightgbm as lgb\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n","from sklearn.ensemble import HistGradientBoostingRegressor\n","from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from google.colab import drive\n","\n","# Mount\n","if not os.path.exists('/content/drive/MyDrive'):\n","    drive.mount('/content/drive')\n","else:\n","    print('Drive already mounted!')\n","\n","PREP_IN = '/content/drive/MyDrive/dsp-poc/data/df_preprocessed.parquet'\n","ART_DIR = '/content/drive/MyDrive/dsp-poc/artifacts'\n","os.makedirs(ART_DIR, exist_ok=True)\n","\n","df = pd.read_parquet(PREP_IN)\n","print('Loaded preprocessed:', df.shape)\n","\n","# Features & bins\n","exclude_cols = ['RUL', 'unit', 'cycle', 'fail_in_H']\n","sensor_cols = [c for c in df.columns if c not in exclude_cols]\n","\n","rul_max = float(df['RUL'].max())\n","bin_edges = [0, 30, 200, 500, rul_max + 1e-9]\n","df['rul_bin'] = pd.cut(df['RUL'], bins=bin_edges, include_lowest=True)\n","\n","X = df[sensor_cols].copy()\n","y = df['RUL'].astype(float).copy()\n","bins = df['rul_bin'].astype(str)\n","\n","# Stratified 60/40 split\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.40, random_state=42)\n","for train_idx, test_idx in sss.split(X, bins):\n","    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n","    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n","    bins_train, bins_test = bins.iloc[train_idx], bins.iloc[test_idx]\n","\n","# Internal val split\n","sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n","for tr_idx, val_idx in sss_val.split(X_train, bins_train):\n","    X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n","    y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n","\n","# Utilities\n","np.random.seed(42)\n","\n","def rmse(y_true, y_pred):\n","    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n","\n","def evaluate_model(name, y_true, y_pred):\n","    return { 'Model': name, 'RMSE': rmse(y_true, y_pred), 'MAE': float(mean_absolute_error(y_true, y_pred)), 'R2': float(r2_score(y_true, y_pred)) }\n","\n","metrics = []\n","\n","# 1) RandomForest\n","rf = RandomForestRegressor(n_estimators=700, max_depth=16, min_samples_leaf=25, max_features='sqrt', n_jobs=-1, random_state=42)\n","rf.fit(X_tr, y_tr)\n","y_pred_rf = rf.predict(X_test)\n","metrics.append(evaluate_model('RandomForest', y_test, y_pred_rf))\n","\n","# 2) HistGB\n","hgb = HistGradientBoostingRegressor(max_depth=6, learning_rate=0.06, max_iter=800, min_samples_leaf=20, l2_regularization=1.0, random_state=42)\n","hgb.fit(X_tr, y_tr)\n","y_pred_hgb = hgb.predict(X_test)\n","metrics.append(evaluate_model('HistGB', y_test, y_pred_hgb))\n","\n","# 3) LightGBM baseline\n","lgbm = lgb.LGBMRegressor(objective='regression', learning_rate=0.05, num_leaves=31, max_depth=-1, min_child_samples=30, subsample=0.8, colsample_bytree=0.9, reg_lambda=1.0, n_estimators=5000, random_state=42)\n","lgbm.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], eval_metric='rmse', callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=True), lgb.log_evaluation(period=200)])\n","best_iter = getattr(lgbm, 'best_iteration_', None)\n","y_pred_lgbm = lgbm.predict(X_test, num_iteration=best_iter) if best_iter else lgbm.predict(X_test)\n","metrics.append(evaluate_model('LightGBM', y_test, y_pred_lgbm))\n","\n","# 4) CatBoost baseline\n","cat = CatBoostRegressor(loss_function='RMSE', eval_metric='RMSE', depth=6, learning_rate=0.05, l2_leaf_reg=3.0, bootstrap_type='Bernoulli', subsample=0.8, random_strength=0.5, iterations=5000, early_stopping_rounds=200, use_best_model=True, random_seed=42, verbose=200)\n","cat.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n","y_pred_cat = cat.predict(X_test)\n","metrics.append(evaluate_model('CatBoost', y_test, y_pred_cat))\n","\n","import pandas as pd\n","compare_df = pd.DataFrame(metrics).sort_values('RMSE')\n","print('=== Test Metrics (Baseline) ===')\n","print(compare_df)\n","\n","# Event flags for sensor_04/05\n","\n","def add_event_flags(df_in):\n","    df2 = df_in.copy()\n","    def robust_stats(s):\n","        q1, q3 = s.quantile(0.25), s.quantile(0.75)\n","        iqr = q3 - q1\n","        med = s.median()\n","        return med, q1, q3, iqr\n","    for s in ['sensor_04', 'sensor_05']:\n","        if s not in df2.columns:\n","            print(f'Warning: {s} not found; skipping flags.')\n","            continue\n","        med, q1, q3, iqr = robust_stats(df2[s])\n","        safe_iqr = iqr if iqr != 0 else 1.0\n","        df2[f'{s}_drop_flag']  = (df2[s] < (q1 - 1.5*safe_iqr)).astype(int)\n","        df2[f'{s}_spike_flag'] = (df2[s] > (q3 + 1.5*safe_iqr)).astype(int)\n","        df2[f'{s}_dev_med_iqr'] = (df2[s] - med) / safe_iqr\n","        unit_stats = df2.groupby('unit')[s].agg(['median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)])\n","        unit_stats.columns = ['u_med', 'u_q1', 'u_q3']\n","        df2 = df2.join(unit_stats, on='unit')\n","        df2[f'{s}_unit_iqr'] = (df2['u_q3'] - df2['u_q1']).replace(0, np.nan).fillna(safe_iqr)\n","        df2[f'{s}_dev_unit'] = (df2[s] - df2['u_med']) / df2[f'{s}_unit_iqr']\n","        df2.drop(columns=['u_med','u_q1','u_q3'], inplace=True)\n","    return df2\n","\n","# Flagged dataset\n","df_flags = add_event_flags(df)\n","flag_cols = [c for c in df_flags.columns if c.endswith('_drop_flag') or c.endswith('_spike_flag') or c.endswith('_dev_med_iqr') or c.endswith('_dev_unit')]\n","X2 = df_flags[sensor_cols + flag_cols].copy()\n","y2 = df_flags['RUL'].astype(float).copy()\n","\n","# Split again with same strategy\n","bins2 = df_flags['rul_bin'].astype(str)\n","sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.40, random_state=42)\n","for train_idx, test_idx in sss2.split(X2, bins2):\n","    X2_train, X2_test = X2.iloc[train_idx], X2.iloc[test_idx]\n","    y2_train, y2_test = y2.iloc[train_idx], y2.iloc[test_idx]\n","    bins2_train, bins2_test = bins2.iloc[train_idx], bins2.iloc[test_idx]\n","\n","sss2_val = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n","for tr_idx, val_idx in sss2_val.split(X2_train, bins2_train):\n","    X2_tr, X2_val = X2_train.iloc[tr_idx], X2_train.iloc[val_idx]\n","    y2_tr, y2_val = y2_train.iloc[tr_idx], y2_train.iloc[val_idx]\n","\n","# Train again with flags\n","metrics2 = []\n","\n","rf2 = RandomForestRegressor(n_estimators=700, max_depth=16, min_samples_leaf=25, max_features='sqrt', n_jobs=-1, random_state=42)\n","rf2.fit(X2_tr, y2_tr)\n","y2_pred_rf = rf2.predict(X2_test)\n","metrics2.append(evaluate_model('RandomForest+Flags', y2_test, y2_pred_rf))\n","\n","hgb2 = HistGradientBoostingRegressor(max_depth=6, learning_rate=0.06, max_iter=800, min_samples_leaf=20, l2_regularization=1.0, random_state=42)\n","hgb2.fit(X2_tr, y2_tr)\n","y2_pred_hgb = hgb2.predict(X2_test)\n","metrics2.append(evaluate_model('HistGB+Flags', y2_test, y2_pred_hgb))\n","\n","lgbm2 = lgb.LGBMRegressor(objective='regression', learning_rate=0.05, num_leaves=31, max_depth=-1, min_child_samples=30, subsample=0.8, colsample_bytree=0.9, reg_lambda=1.0, n_estimators=5000, random_state=42)\n","lgbm2.fit(X2_tr, y2_tr, eval_set=[(X2_val, y2_val)], eval_metric='rmse', callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=True), lgb.log_evaluation(period=200)])\n","best_iter2 = getattr(lgbm2, 'best_iteration_', None)\n","y2_pred_lgbm = lgbm2.predict(X2_test, num_iteration=best_iter2) if best_iter2 else lgbm2.predict(X2_test)\n","metrics2.append(evaluate_model('LightGBM+Flags', y2_test, y2_pred_lgbm))\n","\n","cat2 = CatBoostRegressor(loss_function='RMSE', eval_metric='RMSE', depth=6, learning_rate=0.05, l2_leaf_reg=3.0, bootstrap_type='Bernoulli', subsample=0.8, random_strength=0.5, iterations=5000, early_stopping_rounds=200, use_best_model=True, random_seed=42, verbose=200)\n","cat2.fit(X2_tr, y2_tr, eval_set=(X2_val, y2_val))\n","y2_pred_cat = cat2.predict(X2_test)\n","metrics2.append(evaluate_model('CatBoost+Flags', y2_test, y2_pred_cat))\n","\n","compare_df2 = pd.DataFrame(metrics2).sort_values('RMSE')\n","print('=== Test Metrics AFTER adding event flags ===')\n","print(compare_df2)\n","\n","# Decide & save best\n","combined = pd.concat([pd.DataFrame(compare_df).assign(Round='Baseline'), pd.DataFrame(compare_df2).assign(Round='WithFlags')], ignore_index=True)\n","print('=== Combined Comparison (Baseline vs WithFlags) ===')\n","print(combined.sort_values(['Round','RMSE']))\n","\n","best_row = combined.sort_values(['RMSE','MAE']).iloc[0]\n","best_model_name = best_row['Model']\n","print(f'Selected best model: {best_model_name} ({best_row[\"Round\"]})')\n","\n","from joblib import dump\n","if best_model_name == 'RandomForest':\n","    dump(rf, os.path.join(ART_DIR, 'best_rf.joblib'))\n","elif best_model_name == 'HistGB':\n","    dump(hgb, os.path.join(ART_DIR, 'best_hgb.joblib'))\n","elif best_model_name == 'LightGBM':\n","    dump(lgbm, os.path.join(ART_DIR, 'best_lgbm.joblib'))\n","elif best_model_name == 'CatBoost':\n","    cat.save_model(os.path.join(ART_DIR, 'best_catboost.cbm'))\n","elif best_model_name == 'RandomForest+Flags':\n","    dump(rf2, os.path.join(ART_DIR, 'best_rf_flags.joblib'))\n","elif best_model_name == 'HistGB+Flags':\n","    dump(hgb2, os.path.join(ART_DIR, 'best_hgb_flags.joblib'))\n","elif best_model_name == 'LightGBM+Flags':\n","    dump(lgbm2, os.path.join(ART_DIR, 'best_lgbm_flags.joblib'))\n","elif best_model_name == 'CatBoost+Flags':\n","    cat2.save_model(os.path.join(ART_DIR, 'best_catboost_flags.cbm'))\n","\n","pd.DataFrame(compare_df).to_csv(os.path.join(ART_DIR, 'metrics_baseline.csv'), index=False)\n","pd.DataFrame(compare_df2).to_csv(os.path.join(ART_DIR, 'metrics_with_flags.csv'), index=False)\n","combined.to_csv(os.path.join(ART_DIR, 'metrics_combined.csv'), index=False)\n","\n","print(f'Artifacts saved to: {ART_DIR}')\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}